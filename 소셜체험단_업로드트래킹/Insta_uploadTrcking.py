#https://docs.google.com/spreadsheets/d/1RdnS9IsC1TbTi356J5W-Pb66oaJ7xUhVZr-pTlJTwxQ/edit?gid=0#gid=0



# ì „ì—­ ë³€ìˆ˜ë¡œ SHEET_NAMEê³¼ SPREADSHEET_ID ì„ ì–¸
SHEET_NAME = None
SPREADSHEET_ID = None
PROCESSED_USERNAMES = set()  # ì²˜ë¦¬ëœ usernameì„ ì¶”ì í•˜ëŠ” ì „ì—­ ë³€ìˆ˜

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
import time
import os
import shutil
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from datetime import datetime, timezone, timedelta
import json
import random
from googleapiclient.discovery import build
import sys
from urllib.parse import urlparse, urlunsplit

# auth.py íŒŒì¼ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from auth import get_credentials

def get_sheet_list(service, spreadsheet_id):
    """ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì˜ ëª¨ë“  ì‹œíŠ¸ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    try:
        spreadsheet = service.spreadsheets().get(spreadsheetId=spreadsheet_id).execute()
        sheets = spreadsheet.get('sheets', [])
        return [(i+1, sheet['properties']['title']) for i, sheet in enumerate(sheets)]
    except Exception as e:
        print(f"ì‹œíŠ¸ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return []

def extract_spreadsheet_id(url):
    """ìŠ¤í”„ë ˆë“œì‹œíŠ¸ URLì—ì„œ IDë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        # URLì—ì„œ ID ë¶€ë¶„ ì¶”ì¶œ
        if '/d/' in url:
            # /d/ ë‹¤ìŒì— ì˜¤ëŠ” ID ì¶”ì¶œ
            id_part = url.split('/d/')[1]
            # IDëŠ” ë³´í†µ 44ìë¦¬ì´ë©°, ê·¸ ì´í›„ì˜ ë¶€ë¶„ì€ ì œê±°
            spreadsheet_id = id_part.split('/')[0]
            return spreadsheet_id
        else:
            # URLì´ ì•„ë‹Œ ê²½ìš° ì…ë ¥ê°’ì„ ê·¸ëŒ€ë¡œ ë°˜í™˜
            return url.strip()
    except Exception as e:
        print(f"URLì—ì„œ ID ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return url.strip()

def select_sheet():
    """ì‚¬ìš©ìê°€ ì‹œíŠ¸ë¥¼ ì„ íƒí•˜ëŠ” í•¨ìˆ˜"""
    global SHEET_NAME, SPREADSHEET_ID  # ì „ì—­ ë³€ìˆ˜ ì‚¬ìš© ì„ ì–¸
    
    # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ID ì…ë ¥ ë°›ê¸°
    while True:
        spreadsheet_input = input("\nìŠ¤í”„ë ˆë“œì‹œíŠ¸ URL ë˜ëŠ” IDë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        if spreadsheet_input:
            SPREADSHEET_ID = extract_spreadsheet_id(spreadsheet_input)
            break
        print("ìŠ¤í”„ë ˆë“œì‹œíŠ¸ URL ë˜ëŠ” IDë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    # Google Sheets API ì¸ì¦ ë° ì„œë¹„ìŠ¤ ê°ì²´ ìƒì„±
    creds = get_credentials()
    service = build('sheets', 'v4', credentials=creds)
    
    # ì‹œíŠ¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    sheets = get_sheet_list(service, SPREADSHEET_ID)
    
    if not sheets:
        print("ì‹œíŠ¸ ëª©ë¡ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ì‹œíŠ¸ ëª©ë¡ ì¶œë ¥
    print("\n=== ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œíŠ¸ ëª©ë¡ ===")
    for num, title in sheets:
        print(f"{num}. {title}")
    
    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    while True:
        try:
            choice = int(input("\nì‚¬ìš©í•  ì‹œíŠ¸ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”: "))
            if 1 <= choice <= len(sheets):
                SHEET_NAME = sheets[choice-1][1]  # ì „ì—­ ë³€ìˆ˜ ì—…ë°ì´íŠ¸
                print(f"\nì„ íƒëœ ì‹œíŠ¸: {SHEET_NAME}")
                return SHEET_NAME
            else:
                print(f"1ë¶€í„° {len(sheets)} ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        except ValueError:
            print("ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

def clean_url(url):
    """URLì—ì„œ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ë¥¼ ì œê±°í•˜ëŠ” í•¨ìˆ˜"""
    print(f"\n[URL ì •ê·œí™” ì‹œì‘] ì›ë³¸ URL: {url}")
    parsed = urlparse(url)
    print(f"URL íŒŒì‹± ê²°ê³¼:")
    print(f"- scheme: {parsed.scheme}")
    print(f"- netloc: {parsed.netloc}")
    print(f"- path: {parsed.path}")
    print(f"- query: {parsed.query}")
    print(f"- fragment: {parsed.fragment}")
    
    clean = urlunsplit((parsed.scheme, parsed.netloc, parsed.path, '', ''))
    print(f"[URL ì •ê·œí™” ì™„ë£Œ] ì •ê·œí™”ëœ URL: {clean}")
    return clean

def clear_chrome_data(user_data_dir, keep_login=True):
    default_dir = os.path.join(user_data_dir, 'Default')
    if not os.path.exists(default_dir):
        print("Default ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    dirs_to_clear = ['Cache', 'Code Cache', 'GPUCache']
    files_to_clear = ['History', 'Visited Links', 'Web Data']
    
    for dir_name in dirs_to_clear:
        dir_path = os.path.join(default_dir, dir_name)
        if os.path.exists(dir_path):
            shutil.rmtree(dir_path)
            print(f"{dir_name} ë””ë ‰í† ë¦¬ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")

    if not keep_login:
        files_to_clear.extend(['Cookies', 'Login Data'])

    for file_name in files_to_clear:
        file_path = os.path.join(default_dir, file_name)
        if os.path.exists(file_path):
            os.remove(file_path)
            print(f"{file_name} íŒŒì¼ì„ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")

def is_within_period(date_str, weeks):
    try:
        post_date = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
        period_ago = datetime.now(timezone.utc) - timedelta(weeks=weeks)
        return post_date >= period_ago
    except Exception as e:
        print(f"ë‚ ì§œ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False

def crawl_instagram_posts(driver, post_url, weeks, username, keyword):
    try:
        # ê²Œì‹œë¬¼ ì¹´ìš´í„° ì´ˆê¸°í™” (ê¸°ê°„ ë‚´ ëª¨ë“  ê²Œì‹œë¬¼ ì¹´ìš´íŠ¸)
        total_posts_in_period = 0
        keyword_posts = []  # í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²Œì‹œë¬¼ ì €ì¥
        
        # ì—¬ëŸ¬ í‚¤ì›Œë“œ ì²˜ë¦¬ (ì‰¼í‘œë¡œ ë¶„ë¦¬)
        raw_keywords = [k.strip() for k in keyword.split(',') if k.strip()]
        # ê° í‚¤ì›Œë“œë³„ë¡œ ë„ì–´ì“°ê¸° ì œê±° ë²„ì „ë„ í¬í•¨
        keyword_variations = []
        for k in raw_keywords:
            keyword_variations.append(k.lower())
            keyword_variations.append(k.lower().replace(' ', ''))
        print(f"\nê²€ìƒ‰ í‚¤ì›Œë“œ ë³€í˜•: {keyword_variations}")
        
        # ì²« ë²ˆì§¸ í”¼ë“œ ê²Œì‹œë¬¼ì´ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "div._aagv"))
        )
        
        # ì ì‹œ ëŒ€ê¸°
        time.sleep(3)
        
        # ì²« ë²ˆì§¸ ê²Œì‹œë¬¼ ì°¾ê¸°
        first_post = driver.find_element(By.CSS_SELECTOR, "div._aagv")
        
        # ë¶€ëª¨ ìš”ì†Œë¡œ ì´ë™í•˜ì—¬ ë§í¬ ì°¾ê¸°
        parent = first_post.find_element(By.XPATH, "./ancestor::a")
        post_link = parent.get_attribute("href")
        
        # JavaScriptë¡œ ì²« ë²ˆì§¸ ê²Œì‹œë¬¼ í´ë¦­
        print(f"\nì²« ë²ˆì§¸ ê²Œì‹œë¬¼({post_link})ì„ í´ë¦­í•©ë‹ˆë‹¤...")
        driver.execute_script("arguments[0].click();", parent)
        
        # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
        time.sleep(3)
        
        try:
            # ê²Œì‹œë¬¼ ì •ë³´ ì¶”ì¶œ
            post_data = {}
            
            # ì‘ì„±ì ID ì¶”ì¶œ (ì—¬ëŸ¬ ì„ íƒì ì‹œë„)
            try:
                print("\n[ì‘ì„±ì ì •ë³´ ì¶”ì¶œ ì‹œë„]")
                # ì—¬ëŸ¬ ê°€ëŠ¥í•œ ì„ íƒì ì‹œë„
                selectors = [
                    "a[role='link'][tabindex='0']",  # ê¸°ì¡´ ì„ íƒì
                    "header a[role='link']",         # í—¤ë” ë‚´ ë§í¬
                    "div._a9zr a[role='link']",      # ê²Œì‹œë¬¼ í—¤ë” ë‚´ ë§í¬
                    "div._a9zr h2._a9zc"            # ê²Œì‹œë¬¼ í—¤ë” ë‚´ í…ìŠ¤íŠ¸
                ]
                
                author_found = False
                for selector in selectors:
                    try:
                        print(f"ì„ íƒì ì‹œë„: {selector}")
                        author_element = driver.find_element(By.CSS_SELECTOR, selector)
                        if author_element.text.strip():
                            post_data['author'] = author_element.text.strip()
                            print(f"ì‘ì„±ì ì •ë³´ ì¶”ì¶œ ì„±ê³µ: {post_data['author']}")
                            author_found = True
                            break
                    except Exception as e:
                        print(f"ì„ íƒì {selector} ì‹¤íŒ¨: {str(e)}")
                        continue
                
                if not author_found:
                    print("ê²½ê³ : ì‘ì„±ì ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. usernameì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    post_data['author'] = username  # usernameì„ authorë¡œ ì‚¬ìš©
                
            except Exception as e:
                print(f"ì‘ì„±ì ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                print("usernameì„ authorë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                post_data['author'] = username  # usernameì„ authorë¡œ ì‚¬ìš©
            
            # ë³¸ë¬¸ ë‚´ìš© ì¶”ì¶œ
            try:
                content_element = driver.find_element(By.CSS_SELECTOR, "h1._ap3a._aaco._aacu._aacx._aad7._aade")
                post_data['content'] = content_element.text  # ì „ì²´ ë‚´ìš© ì €ì¥
                
                # ê²Œì‹œ ë‚ ì§œ ì¶”ì¶œ
                time_element = driver.find_element(By.CSS_SELECTOR, "time._a9ze._a9zf")
                post_date = time_element.get_attribute('datetime')
                
                # í‚¤ì›Œë“œ ê²€ìƒ‰ (ëª¨ë“  í‚¤ì›Œë“œ ë³€í˜•ì´ ë³¸ë¬¸ì— í¬í•¨ë˜ì–´ì•¼ í•¨)
                content_lower = post_data['content'].lower().replace(' ', '')
                if all(k.replace(' ', '') in content_lower for k in raw_keywords):
                    keyword_posts.append({
                        'url': driver.current_url,
                        'content': post_data['content'],
                        'date': post_date
                    })
                    print(f"\nâœ… ëª¨ë“  í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²Œì‹œë¬¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                    print(f"ê²Œì‹œë¬¼ ë‚´ìš©: {post_data['content'][:100]}...")  # ë‚´ìš© ì¼ë¶€ ì¶œë ¥
                
            except Exception as e:
                print(f"\në³¸ë¬¸ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ ë‚´ìš©ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
                post_data['content'] = ""  # ë¹ˆ ë‚´ìš©ìœ¼ë¡œ ì„¤ì •
            
            # ê²Œì‹œ ë‚ ì§œ ì¶”ì¶œ
            time_element = driver.find_element(By.CSS_SELECTOR, "time._a9ze._a9zf")
            post_date = time_element.get_attribute('datetime')
            
            # ì²˜ìŒ 3ê°œì˜ ê²Œì‹œë¬¼ì€ í•€ê³ ì • ê°€ëŠ¥ì„± ë•Œë¬¸ì— ë¬´ì¡°ê±´ í™•ì¸
            if total_posts_in_period < 3:
                total_posts_in_period += 1
                print(f"í•€ê³ ì • ê°€ëŠ¥ì„± ìˆëŠ” ê²Œì‹œë¬¼ {total_posts_in_period}/3 í™•ì¸ ì¤‘...")
            else:
                # 4ë²ˆì§¸ ê²Œì‹œë¬¼ë¶€í„° ê¸°ê°„ ì²´í¬
                if not is_within_period(post_date, weeks):
                    print(f"\n{weeks}ì£¼ ì´ì „ ê²Œì‹œë¬¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. í¬ë¡¤ë§ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    return total_posts_in_period, keyword_posts
                total_posts_in_period += 1  # ê¸°ê°„ ë‚´ ê²Œì‹œë¬¼ ì¹´ìš´íŠ¸ ì¦ê°€
            
            print(f"ê¸°ê°„ ë‚´ ì´ ê²Œì‹œë¬¼ ìˆ˜: {total_posts_in_period}")
            
            # ë‹¤ìŒ í”¼ë“œë¡œ ì´ë™ (1ì£¼ì¼ ì´ë‚´ì˜ ëª¨ë“  í”¼ë“œ)
            i = 1
            while True:  # ë¬´í•œ ë£¨í”„ë¡œ ë³€ê²½
                # ê²Œì‹œë¬¼ 120ê°œ ì œí•œ ì²´í¬
                if total_posts_in_period >= 120:
                    print("\n120ê°œì˜ ê²Œì‹œë¬¼ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ê³„ì •ìœ¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")
                    return total_posts_in_period, keyword_posts
                    
                try:
                    # í˜„ì¬ URL ì €ì¥
                    current_url = driver.current_url
                    
                    # ë‹¤ìŒ ë²„íŠ¼ ì°¾ê¸°
                    next_button = None
                    selector = "//span[contains(@style, 'rotate(90deg)')]/.."  # 90ë„ íšŒì „ëœ í™”ì‚´í‘œ(ë‹¤ìŒ ë²„íŠ¼)ì˜ ë¶€ëª¨ ìš”ì†Œ
                    
                    print("\në‹¤ìŒ ë²„íŠ¼ ì°¾ëŠ” ì¤‘...")
                    try:
                        next_button = driver.find_element(By.XPATH, selector)
                        if next_button.is_displayed():
                            print("ë‹¤ìŒ ë²„íŠ¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                    except Exception as e:
                        print(f"ë‹¤ìŒ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
                        break
                    
                    if next_button is None:
                        print(f"{i+1}ë²ˆì§¸ í”¼ë“œë¡œ ì´ë™í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìŒ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        break
                    
                    print(f"\n{i+1}ë²ˆì§¸ í”¼ë“œë¡œ ì´ë™í•©ë‹ˆë‹¤...")
                    driver.execute_script("arguments[0].click();", next_button)
                    
                    # ì‹¤ì œ ì‚¬ëŒì²˜ëŸ¼ ëœë¤í•œ ì‹œê°„ ëŒ€ê¸° (ì •ê·œ ë¶„í¬ ì‚¬ìš©)
                    wait_time = abs(random.gauss(2.5, 2))  # í‰ê·  6ì´ˆ, í‘œì¤€í¸ì°¨ 4ì´ˆ
                    # ìµœì†Œ 0.5ì´ˆ, ìµœëŒ€ 50ì´ˆë¡œ ì œí•œ
                    wait_time = max(0.5, min(wait_time, 20.0))
                    print(f"ë‹¤ìŒ í”¼ë“œ ë¡œë”© ëŒ€ê¸° ì¤‘... ({wait_time:.1f}ì´ˆ)")
                    time.sleep(wait_time)
                    
                    # URLì´ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸
                    if driver.current_url == current_url:
                        print(f"{i+1}ë²ˆì§¸ í”¼ë“œë¡œ ì´ë™í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. URLì´ ë³€ê²½ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                        print("í˜„ì¬ URL:", driver.current_url)
                        print("ì´ì „ URL:", current_url)
                        break
                    
                    # ë‹¤ìŒ í”¼ë“œ ì •ë³´ ì¶”ì¶œ
                    next_post_data = {}
                    
                    # ì‘ì„±ì ID ì¶”ì¶œ
                    author_element = driver.find_element(By.CSS_SELECTOR, "a[role='link'][tabindex='0']")
                    next_post_data['author'] = author_element.text.strip() or username  # authorê°€ ë¹„ì–´ìˆìœ¼ë©´ username ì‚¬ìš©
                    
                    # ë³¸ë¬¸ ë‚´ìš© ì¶”ì¶œ
                    try:
                        content_element = driver.find_element(By.CSS_SELECTOR, "h1._ap3a._aaco._aacu._aacx._aad7._aade")
                        next_post_data['content'] = content_element.text  # ì „ì²´ ë‚´ìš© ì €ì¥
                        
                        # ê²Œì‹œ ë‚ ì§œ ì¶”ì¶œ
                        time_element = driver.find_element(By.CSS_SELECTOR, "time._a9ze._a9zf")
                        post_date = time_element.get_attribute('datetime')
                        
                        # í‚¤ì›Œë“œ ê²€ìƒ‰ (ëª¨ë“  í‚¤ì›Œë“œ ë³€í˜•ì´ ë³¸ë¬¸ì— í¬í•¨ë˜ì–´ì•¼ í•¨)
                        content_lower = next_post_data['content'].lower().replace(' ', '')
                        if all(k.replace(' ', '') in content_lower for k in raw_keywords):
                            keyword_posts.append({
                                'url': driver.current_url,
                                'content': next_post_data['content'],
                                'date': post_date
                            })
                            print(f"\nâœ… ëª¨ë“  í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²Œì‹œë¬¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                            print(f"ê²Œì‹œë¬¼ ë‚´ìš©: {next_post_data['content'][:100]}...")  # ë‚´ìš© ì¼ë¶€ ì¶œë ¥
                        
                    except Exception as e:
                        print(f"\në³¸ë¬¸ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ ë‚´ìš©ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
                        next_post_data['content'] = ""  # ë¹ˆ ë‚´ìš©ìœ¼ë¡œ ì„¤ì •
                    
                    # ê²Œì‹œ ë‚ ì§œ ì¶”ì¶œ
                    time_element = driver.find_element(By.CSS_SELECTOR, "time._a9ze._a9zf")
                    post_date = time_element.get_attribute('datetime')
                    
                    # ì²˜ìŒ 3ê°œì˜ ê²Œì‹œë¬¼ì€ í•€ê³ ì • ê°€ëŠ¥ì„± ë•Œë¬¸ì— ë¬´ì¡°ê±´ ë‹¤ìŒìœ¼ë¡œ ë„˜ì–´ê°
                    if total_posts_in_period < 3:
                        total_posts_in_period += 1
                        print(f"í•€ê³ ì • ê°€ëŠ¥ì„± ìˆëŠ” ê²Œì‹œë¬¼ {total_posts_in_period}/3 í™•ì¸ ì¤‘...")
                    else:
                        # 4ë²ˆì§¸ ê²Œì‹œë¬¼ë¶€í„° ê¸°ê°„ ì²´í¬
                        if not is_within_period(post_date, weeks):
                            print(f"\n{weeks}ì£¼ ì´ì „ ê²Œì‹œë¬¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. í¬ë¡¤ë§ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                            return total_posts_in_period, keyword_posts
                        total_posts_in_period += 1  # ê¸°ê°„ ë‚´ ê²Œì‹œë¬¼ ì¹´ìš´íŠ¸ ì¦ê°€
                    
                    print(f"ê¸°ê°„ ë‚´ ì´ ê²Œì‹œë¬¼ ìˆ˜: {total_posts_in_period}")
                    
                    i += 1  # ì¹´ìš´í„° ì¦ê°€
                    
                except Exception as e:
                    print(f"{i+1}ë²ˆì§¸ í”¼ë“œë¡œ ì´ë™í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    break
            
        except Exception as e:
            print(f"ê²Œì‹œë¬¼ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            print("í˜„ì¬ í˜ì´ì§€ ì†ŒìŠ¤:")
            print(driver.page_source[:500])  # í˜ì´ì§€ ì†ŒìŠ¤ì˜ ì¼ë¶€ë¥¼ ì¶œë ¥í•˜ì—¬ ë””ë²„ê¹…

    except Exception as e:
        print(f"ê²Œì‹œë¬¼ì„ í´ë¦­í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print("í˜„ì¬ í˜ì´ì§€ ì†ŒìŠ¤:")
        print(driver.page_source[:500])  # í˜ì´ì§€ ì†ŒìŠ¤ì˜ ì¼ë¶€ë¥¼ ì¶œë ¥í•˜ì—¬ ë””ë²„ê¹…

    return total_posts_in_period, keyword_posts

def take_break(username_count):
    """
    í¬ë¡¤ë§ ì¤‘ íœ´ì‹ ì‹œê°„ì„ ê´€ë¦¬í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        username_count (int): í˜„ì¬ê¹Œì§€ ì²˜ë¦¬í•œ usernameì˜ ìˆ˜
    """
    def show_countdown(seconds, break_type):
        """ì¹´ìš´íŠ¸ë‹¤ìš´ì„ ë³´ì—¬ì£¼ëŠ” ë‚´ë¶€ í•¨ìˆ˜"""
        start_time = time.time()
        while True:
            elapsed_time = int(time.time() - start_time)
            remaining = seconds - elapsed_time
            if remaining <= 0:
                break
            
            if break_type == "ì¤‘ê°„":
                mins, secs = divmod(remaining, 60)
                countdown = f"\r{break_type} íœ´ì‹ ì¤‘: {mins}ë¶„ {secs}ì´ˆ ë‚¨ìŒ...     "
            else:  # "ëŒ€ê·œëª¨"
                hours, remainder = divmod(remaining, 3600)
                mins, secs = divmod(remainder, 60)
                countdown = f"\r{break_type} íœ´ì‹ ì¤‘: {hours}ì‹œê°„ {mins}ë¶„ {secs}ì´ˆ ë‚¨ìŒ...     "
            
            print(countdown, end='', flush=True)
            time.sleep(1)
        print("\ríœ´ì‹ ì™„ë£Œ!            ")  # ì¹´ìš´íŠ¸ë‹¤ìš´ ì¢…ë£Œ í›„ ì¤„ ì •ë¦¬

    # ì¤‘ê°„ íœ´ì‹ (15-25ê°œ usernameë§ˆë‹¤)
    if username_count % random.randint(15, 25) == 0:
        break_time = random.randint(60, 720)  # 1-12ë¶„
        print(f"\nì¤‘ê°„ íœ´ì‹ ì‹œì‘ (ì´ {break_time//60}ë¶„ {break_time%60}ì´ˆ)...")
        show_countdown(break_time, "ì¤‘ê°„")

def load_sheet_data(service, spreadsheet_id):
    """ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì „ì²´ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ë¡œë“œ"""
    try:
        result = service.spreadsheets().values().get(
            spreadsheetId=spreadsheet_id,
            range=f'{SHEET_NAME}!A:M'  # ì‹œíŠ¸ëª… ë³€ìˆ˜ ì‚¬ìš©
        ).execute()
        return result.get('values', [])
    except Exception as e:
        print(f"\nâŒ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def batch_update_sheet(service, spreadsheet_id, updates):
    """ì—¬ëŸ¬ ì…€ì„ í•œ ë²ˆì— ì—…ë°ì´íŠ¸"""
    max_retries = 3  # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
    retry_delay = 2  # ì¬ì‹œë„ ê°„ ëŒ€ê¸° ì‹œê°„(ì´ˆ)
    
    for attempt in range(max_retries):
        try:
            body = {
                'valueInputOption': 'RAW',
                'data': updates
            }
            result = service.spreadsheets().values().batchUpdate(
                spreadsheetId=spreadsheet_id,
                body=body
            ).execute()
            return result
        except Exception as e:
            if attempt < max_retries - 1:  # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ì¬ì‹œë„
                print(f"\nâš ï¸ ì¼ê´„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}). {retry_delay}ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
                print(f"ì˜¤ë¥˜ ë‚´ìš©: {str(e)}")
                time.sleep(retry_delay)
                retry_delay *= 2  # ì§€ìˆ˜ ë°±ì˜¤í”„: ëŒ€ê¸° ì‹œê°„ì„ 2ë°°ë¡œ ì¦ê°€
            else:  # ë§ˆì§€ë§‰ ì‹œë„ì—ì„œë„ ì‹¤íŒ¨
                print(f"\nâŒ ì¼ê´„ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼): {str(e)}")
                return None

def process_next_username(service, spreadsheet_id, usernames):
    """ë‹¤ìŒ í¬ë¡¤ë§í•  ê³„ì •ì„ ì°¾ê³  ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸"""
    global PROCESSED_USERNAMES  # ì „ì—­ ë³€ìˆ˜ ì‚¬ìš©
    max_retries = 3  # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
    retry_delay = 2  # ì¬ì‹œë„ ê°„ ëŒ€ê¸° ì‹œê°„(ì´ˆ)
    
    for attempt in range(max_retries):
        try:
            # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ë¡œë“œ
            result = service.spreadsheets().values().get(
                spreadsheetId=spreadsheet_id,
                range=f'{SHEET_NAME}!A:M'  # ì‹œíŠ¸ëª… ë³€ìˆ˜ ì‚¬ìš©
            ).execute()
            sheet_data = result.get('values', [])
            
            if not sheet_data:
                print("ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None, None, None  # URLë„ Noneìœ¼ë¡œ ë°˜í™˜
            
            # usernameê³¼ í–‰ ë²ˆí˜¸, URL ë§¤í•‘
            username_to_row = {}
            username_to_url = {}

            # í—¤ë” ì œì™¸í•˜ê³  ë°ì´í„° ì²˜ë¦¬
            for i, row in enumerate(sheet_data[1:], start=2):  # 2ë¶€í„° ì‹œì‘ (1-based, í—¤ë” ì œì™¸)
                if not row or len(row) < 2:  # ë¹ˆ í–‰ì´ë‚˜ URLì´ ì—†ëŠ” í–‰ ê±´ë„ˆë›°ê¸°
                    continue
                    
                # Bì—´ì˜ URL í™•ì¸
                url = row[1]
                if not url or 'instagram.com' not in url.lower():
                    continue
                
                # URLì—ì„œ username ì¶”ì¶œ
                username = url.split('instagram.com/')[-1].split('?')[0].split('/')[0]
                
                if username not in usernames:  # í¬ë¡¤ë§ ëŒ€ìƒ ëª©ë¡ì— ì—†ëŠ” ê²½ìš° ê±´ë„ˆë›°ê¸°
                    continue
                
                # ì´ë¯¸ ì²˜ë¦¬í•œ usernameì¸ ê²½ìš° ê±´ë„ˆë›°ê¸°
                if username in PROCESSED_USERNAMES:
                    print(f"\nâ­ï¸ {username} ê³„ì •ì€ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    continue
                
                # Cì—´ì´ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
                content = row[2] if len(row) > 2 else ""
                if content.strip():
                    print(f"\nâ­ï¸ {username} ê³„ì •ì€ ì´ë¯¸ Cì—´ì— ë‚´ìš©ì´ ìˆì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
                    PROCESSED_USERNAMES.add(username)  # ì²˜ë¦¬ëœ usernameìœ¼ë¡œ í‘œì‹œ
                    continue
                    
                username_to_row[username] = i
                username_to_url[username] = url
                PROCESSED_USERNAMES.add(username)  # ì²˜ë¦¬ëœ usernameìœ¼ë¡œ í‘œì‹œ
                
                print(f"\nğŸ”„ {username} ê³„ì • í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                return username_to_row, username, username_to_url[username]

            print("\në” ì´ìƒ í¬ë¡¤ë§í•  ê³„ì •ì´ ì—†ìŠµë‹ˆë‹¤.")
            return username_to_row, None, None

        except Exception as e:
            if attempt < max_retries - 1:  # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ì¬ì‹œë„
                print(f"\nâš ï¸ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}). {retry_delay}ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
                print(f"ì˜¤ë¥˜ ë‚´ìš©: {str(e)}")
                time.sleep(retry_delay)
                retry_delay *= 2  # ì§€ìˆ˜ ë°±ì˜¤í”„: ëŒ€ê¸° ì‹œê°„ì„ 2ë°°ë¡œ ì¦ê°€
            else:  # ë§ˆì§€ë§‰ ì‹œë„ì—ì„œë„ ì‹¤íŒ¨
                print(f"\nâŒ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼): {str(e)}")
                return None, None, None

def update_crawl_date(service, spreadsheet_id, username, post_count, error_log=None):
    """Google Sheetsì˜ Mì—´ì— ê²Œì‹œë¬¼ ìˆ˜ì™€ ì—ëŸ¬ ë¡œê·¸ ì—…ë°ì´íŠ¸"""
    try:
        # ì „ì²´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        result = service.spreadsheets().values().get(
            spreadsheetId=spreadsheet_id,
            range=f'{SHEET_NAME}!A:M'  # ì‹œíŠ¸ëª… ë³€ìˆ˜ ì‚¬ìš©
        ).execute()
        values = result.get('values', [])

        # usernameì´ ìˆëŠ” í–‰ ì°¾ê¸°
        row_number = None
        for i, row in enumerate(values):
            if row and row[0] == username:
                row_number = i + 1  # 1-based index
                break

        if row_number:
            # Mì—´ ì—…ë°ì´íŠ¸
            range_name = f'{SHEET_NAME}!M{row_number}'  # ì‹œíŠ¸ëª… ë³€ìˆ˜ ì‚¬ìš©
            
            # ì—ëŸ¬ê°€ ìˆëŠ” ê²½ìš°ì™€ ì—†ëŠ” ê²½ìš° êµ¬ë¶„
            if error_log:
                body = {
                    'values': [[f"ê²Œì‹œë¬¼ ìˆ˜: {post_count}ê°œ, ì—ëŸ¬: {error_log}"]]
                }
                print(f"\nâŒ {username}ì˜ í¬ë¡¤ë§ ì¤‘ ì—ëŸ¬ ë°œìƒ. ì—ëŸ¬ ë¡œê·¸ê°€ ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                body = {
                    'values': [[f"ê²Œì‹œë¬¼ ìˆ˜: {post_count}ê°œ"]]
                }
                print(f"\nâœ… {username}ì˜ í¬ë¡¤ë§ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ({post_count}ê°œ ê²Œì‹œë¬¼)")

            service.spreadsheets().values().update(
                spreadsheetId=spreadsheet_id,
                range=range_name,
                valueInputOption='RAW',
                body=body
            ).execute()

        else:
            print(f"\nâŒ {username}ì„ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"\nâŒ í¬ë¡¤ë§ ê²°ê³¼ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

def update_crawl_result(service, spreadsheet_id, username, username_to_row, post_count, keyword_posts, error_log=None):
    """í¬ë¡¤ë§ ê²°ê³¼ ì—…ë°ì´íŠ¸"""
    if username not in username_to_row:
        print(f"\nâŒ {username}ì„ í–‰ ë§¤í•‘ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    row_number = username_to_row[username]

    # í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²Œì‹œë¬¼ ì •ë³´ ìƒì„±
    keyword_info = ""
    if keyword_posts:
        # Cì—´ì— ì²« ë²ˆì§¸ í‚¤ì›Œë“œ ê²Œì‹œë¬¼ URL ì €ì¥
        c_update = {
            'range': f'{SHEET_NAME}!C{row_number}',
            'values': [[keyword_posts[0]['url']]]
        }
        batch_update_sheet(service, spreadsheet_id, [c_update])
        
        # Mì—´ì— ì²« ë²ˆì§¸ í‚¤ì›Œë“œ ê²Œì‹œë¬¼ì˜ ë‚ ì§œë§Œ í‘œì‹œ (YYMMDD í˜•ì‹)
        first_post_date = datetime.fromisoformat(keyword_posts[0]['date'].replace('Z', '+00:00'))
        formatted_date = first_post_date.strftime('%y%m%d')
        keyword_info = formatted_date

    # Mì—´ ì—…ë°ì´íŠ¸
    m_update = {
        'range': f'{SHEET_NAME}!M{row_number}',
        'values': [[keyword_info]]
    }

    result = batch_update_sheet(service, spreadsheet_id, [m_update])
    if result:
        if error_log:
            print(f"\nâŒ {username}ì˜ í¬ë¡¤ë§ ì¤‘ ì—ëŸ¬ ë°œìƒ. ì—ëŸ¬ ë¡œê·¸ê°€ ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print(f"\nâœ… {username}ì˜ í¬ë¡¤ë§ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            if keyword_posts:
                print(f"âœ… ì²« ë²ˆì§¸ í‚¤ì›Œë“œ ê²Œì‹œë¬¼ URLì´ Cì—´ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                print(f"âœ… ì²« ë²ˆì§¸ í‚¤ì›Œë“œ ê²Œì‹œë¬¼ì˜ ì‘ì„±ì¼ì´ Mì—´ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                print(f"â„¹ï¸ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²Œì‹œë¬¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

# ë©”ì¸ ì‹¤í–‰ ì½”ë“œ
def main():
    global SHEET_NAME, SPREADSHEET_ID, PROCESSED_USERNAMES  # ì „ì—­ ë³€ìˆ˜ ì‚¬ìš© ì„ ì–¸
    
    # ì²˜ë¦¬ëœ username ì´ˆê¸°í™”
    PROCESSED_USERNAMES.clear()
    
    # ì‹œíŠ¸ ì„ íƒ
    selected_sheet = select_sheet()
    if not selected_sheet:
        print("ì‹œíŠ¸ë¥¼ ì„ íƒí•  ìˆ˜ ì—†ì–´ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    # Google Sheets API ì„¤ì •
    RANGE_NAME = f'{SHEET_NAME}!A:B'  # Aì—´ê³¼ Bì—´ ëª¨ë‘ ê°€ì ¸ì˜¤ê¸°

    # Google Sheets API ì¸ì¦ ë° ì„œë¹„ìŠ¤ ê°ì²´ ìƒì„±
    creds = get_credentials()
    service = build('sheets', 'v4', credentials=creds)

    # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    sheet = service.spreadsheets()
    result = sheet.values().get(spreadsheetId=SPREADSHEET_ID, range=RANGE_NAME).execute()
    values = result.get('values', [])

    if not values:
        print('ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        return

    # í—¤ë” ì œê±° (ì²« ë²ˆì§¸ í–‰ ê±´ë„ˆë›°ê¸°)
    usernames = []
    for row in values[1:]:  # ë¹ˆ í–‰ ì œì™¸
        if len(row) > 1 and row[1]:  # Bì—´ì— URLì´ ìˆëŠ” ê²½ìš°
            url = row[1]
            if 'instagram.com' in url.lower():
                # URLì—ì„œ username ì¶”ì¶œ
                username = url.split('instagram.com/')[-1].split('?')[0].split('/')[0]
                usernames.append(username)
                print(f"ì¶”ê°€ëœ username: {username}")

    if not usernames:
        print('í¬ë¡¤ë§í•  ê³„ì •ì´ ì—†ìŠµë‹ˆë‹¤.')
        return

    print(f"\nì´ {len(usernames)}ê°œì˜ ê³„ì •ì´ í¬ë¡¤ë§ ëŒ€ìƒì…ë‹ˆë‹¤.")

    # í¬ë¡¤ë§ ê¸°ê°„ ì…ë ¥ ë°›ê¸°
    while True:
        try:
            weeks = int(input("\ní¬ë¡¤ë§í•  ê¸°ê°„ì„ ì£¼ ë‹¨ìœ„ë¡œ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 9ì£¼(63ì¼) = 9): "))
            if weeks > 0:
                break
            print("1 ì´ìƒì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        except ValueError:
            print("ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    # ê²€ìƒ‰í•  í‚¤ì›Œë“œ ì…ë ¥ ë°›ê¸°
    keyword = input("\nê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    if not keyword:
        print("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return

    # í‚¤ì›Œë“œ ë³€í˜• ìƒì„± (ì›ë³¸, ë„ì–´ì“°ê¸° ì œê±°)
    keyword_variations = [
        keyword.lower(),  # ì›ë³¸ í‚¤ì›Œë“œ
        keyword.lower().replace(" ", "")  # ë„ì–´ì“°ê¸° ì œê±°
    ]
    print(f"\nê²€ìƒ‰ í‚¤ì›Œë“œ ë³€í˜•: {keyword_variations}")

    # ë¡œê·¸ì¸ ì •ë³´ íŒŒì¼ ê²½ë¡œ ì„¤ì • (ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©)
    login_file_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "0_insta_login.txt")
    with open(login_file_path, 'r', encoding='utf-8') as f:
        profile_name = f.read().strip()

    # ì‚¬ìš©ì ë°ì´í„° ë””ë ‰í† ë¦¬ ì„¤ì • (ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©)
    user_data_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "user_data", profile_name)

    try:
        while True:
            # ë‹¤ìŒ í¬ë¡¤ë§í•  ê³„ì • ì°¾ê¸°
            username_to_row, next_username, next_url = process_next_username(service, SPREADSHEET_ID, usernames)
            
            if not username_to_row or not next_username or not next_url:
                print("\ní¬ë¡¤ë§ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break

            try:
                # Chrome ì˜µì…˜ ì„¤ì •
                options = Options()
                options.add_argument("--start-maximized")
                options.add_experimental_option("detach", True)
                options.add_argument("disable-blink-features=AutomationControlled")
                options.add_experimental_option("excludeSwitches", ["enable-logging"])
                options.add_argument(f"user-data-dir={user_data_dir}")
                options.add_argument("--disable-application-cache")
                options.add_argument("--disable-cache")

                # ìºì‹œì™€ ì„ì‹œ íŒŒì¼ ì •ë¦¬ (ë¡œê·¸ì¸ ì •ë³´ ìœ ì§€)
                clear_chrome_data(user_data_dir)

                # ìƒˆë¡œìš´ Chrome ë“œë¼ì´ë²„ ì‹œì‘
                driver = webdriver.Chrome(options=options)

                print(f"\n{next_username} ê³„ì • í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
                print(f"\ní”„ë¡œí•„ URL({next_url})ë¡œ ì´ë™í•©ë‹ˆë‹¤...")
                driver.get(next_url)
                
                # í”„ë¡œí•„ í˜ì´ì§€ì˜ ì£¼ìš” ìš”ì†Œê°€ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°
                try:
                    # í”„ë¡œí•„ ì´ë¯¸ì§€ë‚˜ ê²Œì‹œë¬¼ ê·¸ë¦¬ë“œê°€ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°
                    WebDriverWait(driver, 10).until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, "div._aagv"))
                    )
                    print("í”„ë¡œí•„ í˜ì´ì§€ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
                except Exception as e:
                    print(f"í”„ë¡œí•„ í˜ì´ì§€ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    raise

                # í¬ë¡¤ë§ ì‹¤í–‰ ë° ê²Œì‹œë¬¼ ìˆ˜ ë°›ê¸°
                post_count, keyword_posts = crawl_instagram_posts(driver, next_url, weeks, next_username, keyword)
                
                # í¬ë¡¤ë§ ê²°ê³¼ ì—…ë°ì´íŠ¸
                update_crawl_result(service, SPREADSHEET_ID, next_username, username_to_row, post_count, keyword_posts)
                
                # ë¸Œë¼ìš°ì € ì¢…ë£Œ
                print(f"\n{next_username} ê³„ì • í¬ë¡¤ë§ ì™„ë£Œ. ë¸Œë¼ìš°ì €ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                driver.quit()
                
                # íœ´ì‹ ì‹œê°„ ê´€ë¦¬
                take_break(usernames.index(next_username) + 1)

            except Exception as e:
                error_message = f"{datetime.now(timezone(timedelta(hours=9))).strftime('%Y-%m-%d %H:%M:%S')} - {str(e)}"
                update_crawl_result(service, SPREADSHEET_ID, next_username, username_to_row, 0, [], error_message)
                if 'driver' in locals():
                    driver.quit()
                continue

    except Exception as e:
        print(f"í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    finally:
        print("\nëª¨ë“  ê³„ì •ì˜ í¬ë¡¤ë§ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        input("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•˜ë ¤ë©´ ì—”í„°ë¥¼ ëˆ„ë¥´ì„¸ìš”...")

if __name__ == "__main__":
    main()
